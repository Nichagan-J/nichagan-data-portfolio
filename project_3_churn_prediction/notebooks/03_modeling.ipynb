{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89843c56",
   "metadata": {},
   "source": [
    "Cell 1: Imports + Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e146ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fc00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\Lenovo\\Desktop\\Portfolio\\data-portfolio-nichagan\\project_3_churn_prediction\n",
      "DATA_PATH: c:\\Users\\Lenovo\\Desktop\\Portfolio\\data-portfolio-nichagan\\project_3_churn_prediction\\data\\processed\\churn_processed.csv\n",
      "Exists: True\n",
      "MODEL_DIR: c:\\Users\\Lenovo\\Desktop\\Portfolio\\data-portfolio-nichagan\\project_3_churn_prediction\\outputs\\models\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Paths (Notebook-safe)\n",
    "# ===============================\n",
    "PROJECT_ROOT = Path.cwd().parent  # notebooks -> project_3_churn_prediction\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"churn_processed.csv\"\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "MODEL_DIR = OUTPUT_DIR / \"models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "print(\"Exists:\", DATA_PATH.exists())\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9acca",
   "metadata": {},
   "source": [
    "Cell 2: Target cleaning (Yes/No -> 0/1) + check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7468d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\Lenovo\\Desktop\\Portfolio\\data-portfolio-nichagan\\project_3_churn_prediction\\notebooks\n",
      "RAW_PATH: c:\\Users\\Lenovo\\Desktop\\Portfolio\\data-portfolio-nichagan\\project_3_churn_prediction\\data\\raw\\telco-customer-churn.csv | Exists: True\n",
      "target_col = Churn\n",
      "\n",
      "Value counts:\n",
      " Churn\n",
      "0    5174\n",
      "1    1869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Normalized value counts:\n",
      " Churn\n",
      "0    0.73463\n",
      "1    0.26537\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- paths (robust for notebooks) ---\n",
    "PROJECT_ROOT = Path.cwd().parent   # now at .../project_3_churn_prediction\n",
    "RAW_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"telco-customer-churn.csv\"\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "# --- target (short) ---\n",
    "target_col = \"Churn\" if \"Churn\" in df.columns else df.columns[-1]\n",
    "df[target_col] = df[target_col].astype(str).str.strip().str.lower().map({\"yes\": 1, \"no\": 0}).astype(int)\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"RAW_PATH:\", RAW_PATH, \"| Exists:\", RAW_PATH.exists())\n",
    "print(\"target_col =\", target_col)\n",
    "print(\"\\nValue counts:\\n\", df[target_col].value_counts())\n",
    "print(\"\\nNormalized value counts:\\n\", df[target_col].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb47aad",
   "metadata": {},
   "source": [
    "Cell 3: Split X/y + Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526398bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped ID column: customerID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5634, 19), (1409, 19))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# Split features/target\n",
    "# ===============================\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# (optional) drop ID column if exists\n",
    "for id_col in [\"customerID\", \"CustomerID\", \"customer_id\", \"Row ID\", \"RowID\"]:\n",
    "    if id_col in X.columns:\n",
    "        X = X.drop(columns=[id_col])\n",
    "        print(\"Dropped ID column:\", id_col)\n",
    "\n",
    "# ===============================\n",
    "# Train/test split (stratify สำคัญมาก)\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db001344",
   "metadata": {},
   "source": [
    "Cell 4: Build preprocess (ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d58df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: 3\n",
      "Categorical cols: 16\n",
      "Example cat cols: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Column types\n",
    "# ===============================\n",
    "num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "print(\"Numeric cols:\", len(num_cols))\n",
    "print(\"Categorical cols:\", len(cat_cols))\n",
    "print(\"Example cat cols:\", cat_cols[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b94c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Preprocess pipelines\n",
    "# ===============================\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e7580",
   "metadata": {},
   "source": [
    "Cell 5: Train baseline models (LogReg + RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25decebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training done.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Model 1: Logistic Regression (baseline)\n",
    "# ===============================\n",
    "logreg_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "# Model 2: Random Forest (strong baseline)\n",
    "# ===============================\n",
    "rf_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Training done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe7d17",
   "metadata": {},
   "source": [
    "Cell 6: Evaluate function + Evaluate both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf9070cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== LogisticRegression ======\n",
      "ROC-AUC: 0.8402981218837996\n",
      "PR-AUC: 0.6351133262986087\n",
      "Confusion Matrix:\n",
      " [[917 118]\n",
      " [172 202]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1035\n",
      "           1       0.63      0.54      0.58       374\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.74      0.71      0.72      1409\n",
      "weighted avg       0.79      0.79      0.79      1409\n",
      "\n",
      "\n",
      "====== RandomForest ======\n",
      "ROC-AUC: 0.8214317083882301\n",
      "PR-AUC: 0.6046770159870083\n",
      "Confusion Matrix:\n",
      " [[916 119]\n",
      " [188 186]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1035\n",
      "           1       0.61      0.50      0.55       374\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.69      0.70      1409\n",
      "weighted avg       0.77      0.78      0.77      1409\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'name': 'LogisticRegression',\n",
       "  'roc_auc': 0.8402981218837996,\n",
       "  'pr_auc': 0.6351133262986087},\n",
       " {'name': 'RandomForest',\n",
       "  'roc_auc': 0.8214317083882301,\n",
       "  'pr_auc': 0.6046770159870083})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test, name=\"model\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n====== {name} ======\")\n",
    "    print(\"ROC-AUC:\", roc)\n",
    "    print(\"PR-AUC:\", pr)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return {\"name\": name, \"roc_auc\": roc, \"pr_auc\": pr}\n",
    "\n",
    "res_lr = evaluate(logreg_model, X_test, y_test, \"LogisticRegression\")\n",
    "res_rf = evaluate(rf_model, X_test, y_test, \"RandomForest\")\n",
    "\n",
    "res_lr, res_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4b47e",
   "metadata": {},
   "source": [
    "Cell 7: Save best model เป็น best_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "556d4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved best model: LogisticRegression\n",
      "Path: c:\\Users\\Lenovo\\Desktop\\Portfolio\\data-portfolio-nichagan\\project_3_churn_prediction\\outputs\\models\\best_model.pkl\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Choose best by ROC-AUC\n",
    "# ===============================\n",
    "best_model = rf_model if res_rf[\"roc_auc\"] >= res_lr[\"roc_auc\"] else logreg_model\n",
    "best_name = \"RandomForest\" if best_model is rf_model else \"LogisticRegression\"\n",
    "\n",
    "best_model_path = MODEL_DIR / \"best_model.pkl\"\n",
    "joblib.dump(best_model, best_model_path)\n",
    "\n",
    "print(\"✅ Saved best model:\", best_name)\n",
    "print(\"Path:\", best_model_path)\n",
    "print(\"Exists:\", best_model_path.exists())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
